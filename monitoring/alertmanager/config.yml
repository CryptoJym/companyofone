global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@companyofone.ai'
  smtp_auth_username: 'alerts@companyofone.ai'
  smtp_auth_password: 'your-email-password'
  resolve_timeout: 5m

templates:
  - '/etc/alertmanager/templates/*.tmpl'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'web.hook'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      continue: true
    - match:
        severity: warning
      receiver: 'warning-alerts'
      continue: true
    - match:
        alertname: ServiceDown
      receiver: 'service-down-alerts'
      continue: true

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'
        send_resolved: true

  - name: 'critical-alerts'
    email_configs:
      - to: 'admin@companyofone.ai'
        subject: 'üö® CRITICAL Alert: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        body: |
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Severity:** {{ .Labels.severity }}
          **Instance:** {{ .Labels.instance }}
          **Started:** {{ .StartsAt }}
          {{ end }}
        headers:
          Priority: '1'
    # Slack webhook for critical alerts
    slack_configs:
      - api_url: 'YOUR_SLACK_WEBHOOK_URL'
        channel: '#alerts-critical'
        title: 'üö® Critical Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Instance:* {{ .Labels.instance }}
          {{ end }}
        color: 'danger'
        send_resolved: true

  - name: 'warning-alerts'
    email_configs:
      - to: 'team@companyofone.ai'
        subject: '‚ö†Ô∏è  Warning Alert: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        body: |
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Severity:** {{ .Labels.severity }}
          **Instance:** {{ .Labels.instance }}
          **Started:** {{ .StartsAt }}
          {{ end }}
    # Slack webhook for warning alerts
    slack_configs:
      - api_url: 'YOUR_SLACK_WEBHOOK_URL'
        channel: '#alerts-warning'
        title: '‚ö†Ô∏è Warning Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Instance:* {{ .Labels.instance }}
          {{ end }}
        color: 'warning'
        send_resolved: true

  - name: 'service-down-alerts'
    # PagerDuty integration for service down alerts
    pagerduty_configs:
      - routing_key: 'YOUR_PAGERDUTY_ROUTING_KEY'
        description: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        details:
          alert: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
          description: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
          instance: '{{ range .Alerts }}{{ .Labels.instance }}{{ end }}'
          severity: '{{ range .Alerts }}{{ .Labels.severity }}{{ end }}'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']